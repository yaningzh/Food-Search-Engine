{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "recipe2 = []\n",
        "r2 = csv.reader(open('/content/recipes2.csv'))\n",
        "r2_header = next(r2)\n",
        "for row in r2:\n",
        "    recipe2.append(row[1])"
      ],
      "metadata": {
        "id": "IxUATpre97iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "recipe3 = []\n",
        "r3 = csv.reader(open('/content/recipes3.csv'))\n",
        "r3_header = next(r3)\n",
        "for row in r3:\n",
        "    recipe3.append(row[1])"
      ],
      "metadata": {
        "id": "2i1KWtCk97iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "recipe0 = []\n",
        "r0 = csv.reader(open('/content/scraped-07-05-21.csv'))\n",
        "r0_header = next(r0)\n",
        "for row in r0:\n",
        "    recipe0.append(row[1])"
      ],
      "metadata": {
        "id": "lmWRSKgE97iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_urls = list(set(recipe3+recipe0+recipe2))"
      ],
      "metadata": {
        "id": "FVFPq3hY_N3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recipe-scrapers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9198be25-0085-477c-daa2-64801b4859ce",
        "id": "9EYmHqGO97ir"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting recipe-scrapers\n",
            "  Downloading recipe_scrapers-14.26.0-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4>=4.10.0\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 54.6 MB/s \n",
            "\u001b[?25hCollecting isodate>=0.6.1\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 606 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.1 in /usr/local/lib/python3.8/dist-packages (from recipe-scrapers) (2.23.0)\n",
            "Collecting extruct>=0.8.0\n",
            "  Downloading extruct-0.14.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from extruct>=0.8.0->recipe-scrapers) (1.15.0)\n",
            "Collecting mf2py\n",
            "  Downloading mf2py-1.1.2.tar.gz (25 kB)\n",
            "Collecting jstyleson\n",
            "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
            "Collecting html-text>=0.5.1\n",
            "  Downloading html_text-0.5.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting rdflib>=6.0.0\n",
            "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
            "\u001b[K     |████████████████████████████████| 500 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from extruct>=0.8.0->recipe-scrapers) (4.9.1)\n",
            "Collecting pyrdfa3\n",
            "  Downloading pyRdfa3-3.5.3-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 49.3 MB/s \n",
            "\u001b[?25hCollecting w3lib\n",
            "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from rdflib>=6.0.0->extruct>=0.8.0->recipe-scrapers) (57.4.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from rdflib>=6.0.0->extruct>=0.8.0->recipe-scrapers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.1->recipe-scrapers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.1->recipe-scrapers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.1->recipe-scrapers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.1->recipe-scrapers) (1.24.3)\n",
            "Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from mf2py->extruct>=0.8.0->recipe-scrapers) (1.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from html5lib>=1.0.1->mf2py->extruct>=0.8.0->recipe-scrapers) (0.5.1)\n",
            "Building wheels for collected packages: jstyleson, mf2py\n",
            "  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2401 sha256=7b462dad81b5289753347a2e7e0dfdf466d9f030df6eb4df93946b0b6d07dda2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/3a/8e/dad087c08bb0e4c94d03433ccc0972ee29707dff8e6c5f5e1b\n",
            "  Building wheel for mf2py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mf2py: filename=mf2py-1.1.2-py3-none-any.whl size=23242 sha256=b342e43bb32ba326b82efe6c932361957d2169b4d7830a89cab6658cc70e6d8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/86/25/8b1eee6d115e532e416f508dee0758d2093c9beb7923682924\n",
            "Successfully built jstyleson mf2py\n",
            "Installing collected packages: soupsieve, isodate, rdflib, beautifulsoup4, w3lib, pyrdfa3, mf2py, jstyleson, html-text, extruct, recipe-scrapers\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.11.1 extruct-0.14.0 html-text-0.5.2 isodate-0.6.1 jstyleson-0.0.2 mf2py-1.1.2 pyrdfa3-3.5.3 rdflib-6.2.0 recipe-scrapers-14.26.0 soupsieve-2.3.2.post1 w3lib-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Recipe:\n",
        "    title: str\n",
        "    url: str\n",
        "    total_time: str\n",
        "    rating: str\n",
        "    yields: str\n",
        "    ingredients: str\n",
        "    instructions: str\n",
        "    image: str\n",
        "    calories: str\n",
        "    carbohydrateContents: str\n",
        "    cholesterolContents: str\n",
        "    fiberContents: str\n",
        "    proteinContents: str\n",
        "    saturatedFatContents: str\n",
        "    sodiumContents: str\n",
        "    sugarContents: str\n",
        "    fatContents: str\n",
        "    unsaturatedFatContents: str"
      ],
      "metadata": {
        "id": "NDBChLNxBRiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from recipe_scrapers import scrape_me\n",
        "from tqdm import tqdm\n",
        "all_recipes = []\n",
        "# give the url as a string, it can be url from any site listed below\n",
        "for url in tqdm(all_urls):\n",
        "    try:\n",
        "        scraper = scrape_me(url)\n",
        "\n",
        "        title = scraper.title()\n",
        "        title = title.replace(u\"\\xae\", '').replace(u\"\\xa9\", '').replace(u\"\\u2122\", '')\n",
        "\n",
        "        total_time = scraper.total_time()\n",
        "        try:\n",
        "            rating = scraper.ratings()\n",
        "        except:\n",
        "            rating = 'N/A'\n",
        "        try:\n",
        "            yields = scraper.yields()\n",
        "        except:\n",
        "            yields = 'N/A'\n",
        "        ingredients = scraper.ingredients()\n",
        "        instructions = scraper.instructions()  # or alternatively for results as a Python list: scraper.instructions_list()\n",
        "        instructions = instructions.replace(u\"\\xae\", '').replace(u\"\\xa9\", '').replace(u\"\\u2122\", '')\n",
        "        \n",
        "        try:\n",
        "            image = scraper.image()\n",
        "        except:\n",
        "            image = 'N/A'\n",
        "        n = scraper.nutrients()\n",
        "\n",
        "        if 'calories' in n.keys():\n",
        "            calories = n['calories']\n",
        "        else:\n",
        "            calories = 'N/A'\n",
        "\n",
        "        if 'carbohydrateContent' in n.keys():\n",
        "            carbohydrateContents = n['carbohydrateContent']\n",
        "        else:\n",
        "            carbohydrateContents = 'N/A'\n",
        "\n",
        "        if 'cholesterolContent' in n.keys():\n",
        "            cholesterolContents = n['cholesterolContent']\n",
        "        else:\n",
        "            cholesterolContents = 'N/A'\n",
        "\n",
        "        if 'fiberContent' in n.keys():\n",
        "            fiberContents = n['fiberContent']\n",
        "        else:\n",
        "            fiberContents = 'N/A'\n",
        "            \n",
        "        if 'proteinContent' in n.keys():\n",
        "            proteinContents = n['proteinContent']\n",
        "        else:\n",
        "            proteinContents = 'N/A'\n",
        "\n",
        "        if 'saturatedFatContent' in n.keys():\n",
        "            saturatedFatContents = n['saturatedFatContent']\n",
        "        else:\n",
        "            saturatedFatContents = 'N/A'\n",
        "\n",
        "        if 'sodiumContent' in n.keys():\n",
        "            sodiumContents = n['sodiumContent']\n",
        "        else:\n",
        "            sodiumContents = 'N/A'\n",
        "\n",
        "        if 'sugarContent' in n.keys():\n",
        "            sugarContents = n['sugarContent']\n",
        "        else:\n",
        "            sugarContents = 'N/A'\n",
        "\n",
        "        if 'fatContent' in n.keys():\n",
        "            fatContents = n['fatContent']\n",
        "        else:\n",
        "            fatContents = 'N/A'\n",
        "\n",
        "        if 'unsaturatedFatContent' in n.keys():\n",
        "            unsaturatedFatContents = n['unsaturatedFatContent']\n",
        "        else:\n",
        "            unsaturatedFatContents = 'N/A'\n",
        "        \n",
        "        all_recipes.append(Recipe(title, url, total_time, rating, yields, ingredients, instructions, image, calories, carbohydrateContents, cholesterolContents, fiberContents, proteinContents, saturatedFatContents, sodiumContents, sugarContents, fatContents, unsaturatedFatContents))\n",
        "    except:\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P--Ve4FjD8Sb",
        "outputId": "50f09e36-74f5-4ece-a1a4-5bab2e1ed3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46485/46485 [4:45:37<00:00,  2.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import random\n",
        "\n",
        "N=7\n",
        "def get_docno():\n",
        "    docno = ''.join(random.choices(string.ascii_lowercase + string.ascii_uppercase +\n",
        "                                string.digits, k=N))\n",
        "    return docno"
      ],
      "metadata": {
        "id": "4TCdYTRT2i4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "raw_file = pd.DataFrame({\"title\": [r.title for r in all_recipes],\n",
        "                    \"docno\": [get_docno() for r in all_recipes],\n",
        "                    \"url\": [r.url for r in all_recipes],\n",
        "                    \"total_time\": [r.total_time for r in all_recipes],\n",
        "                    \"rating\": [r.rating for r in all_recipes],\n",
        "                    \"yields\": [r.yields for r in all_recipes],\n",
        "                    \"ingredients\": [r.ingredients for r in all_recipes],\n",
        "                    \"instructions\": [r.instructions for r in all_recipes],\n",
        "                    \"image\": [r.image for r in all_recipes],\n",
        "                    \"calories\": [r.calories for r in all_recipes],\n",
        "                    \"carbohydrateContents\": [r.carbohydrateContents for r in all_recipes],\n",
        "                    \"cholesterolContents\": [r.cholesterolContents for r in all_recipes],\n",
        "                    \"fiberContents\": [r.fiberContents for r in all_recipes],\n",
        "                    \"proteinContents\": [r.proteinContents for r in all_recipes],\n",
        "                    \"saturatedFatContents\": [r.saturatedFatContents for r in all_recipes],\n",
        "                    \"sodiumContents\": [r.sodiumContents for r in all_recipes],\n",
        "                    \"sugarContents\": [r.sugarContents for r in all_recipes],\n",
        "                    \"fatContents\": [r.fatContents for r in all_recipes],\n",
        "                    \"unsaturatedFatContents\": [r.unsaturatedFatContents for r in all_recipes]\n",
        "                    })"
      ],
      "metadata": {
        "id": "_1VbD1eC2nkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_file.to_csv('/content/drive/MyDrive/22fall/549/549project/final/recipes.csv', index=False)"
      ],
      "metadata": {
        "id": "QsXL2NfR2tTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}